########################################################################
[DEFAULT]
########################################################################
# This section named "[DEFAULT]" contains the majority of
# parameters used in the analysis.

# Review filetree
root_data_dir = /Users/zhafen/Data/cgm_modeling_challenge/literature_review
paper_dir = /Users/zhafen/paper_repos/cgm_modeling_challenge_paper
code_dir = ${paper_dir}/literature_review

# Filepaths
tex_fp = ${paper_dir}/main.tex
atlas_fp = ${root_data_dir}/atlas.json
projection_fp = ${root_data_dir}/projection.h5
zotero_atlas_fp = ${root_data_dir}/atlas_zotero.json
zotero_bibtex_fp = ${root_data_dir}/zotero.bib
zotero_projection_fp = ${root_data_dir}/projection_zotero.h5

# Analysis parameters
kernel_size = 16
global_kernel_size = 1000
citation_key = 'Hafen2022b'
emphasis_vector = [
    ( 'molecular', -1. ),
    ( 'molecular cloud', -10. ),
    ( 'emission', -2. ),
    ( 'HVC', -0.5 ),
    ]
emphasis_scaling = 0.5

########################################################################
[SCRIPTS]
########################################################################
# This section named "[SCRIPTS]" contains code that will be run.
# Code will be run in order listed.
# The prefix determines how the code will be handled.

# Get halo data
nb.1 = ${code_dir}/topic_search.py

########################################################################
[DATA PRODUCTS]
########################################################################
# This section helps convert existing pipelines to trove pipelines.
# In particular it will check if the data products exist and mark that part
# of the trove as complete if they do.

nb.1 = output

########################################################################
# Parameter Variations
########################################################################
# These sections are variations on the parameters to explore.
# Each will create a trove of data.
# The section name should be the identifier you would
# like to use for that set of parameters.

[absorption_surveys]
publications = [
    'Shull1996',
    'Tripp2000',
    'Tripp2000a',
    'Penton2004',
    'Tumlinson2011',
    'Bordoloi2011',
    'Werk2014',
    'Lehner2018',
    'Berg2018a',
    'Burchett2018',
    'Burchett2019a',
    'Rudie2019',
    ]

[multicomponent_modeling] # Typically Bayesian analyses
publications = [
    'Liang2017',
    'Liang2018',
    'Haislmaier2020',
    'Sameer2021',
    'Zahedy2021',
    'Marra2021',
    'Marra2022',
    ]
    
[mock_spectra]
search_str = 'mock quasar absorption spectra'
publications = [
    'Hummels2017',
    'Liang2018',
    ]
    
[sample0]
search_str = 'column densities of uniform clouds'
publications = [
    'Ferland2013', # Cloudy
    ]
    
[sample1]
search_str = 'spectra of multi-cloud systems'
publications = [
    'Wijers2019',
    'Wijers2021',
    ]
    
[sample2]
search_str = 'spectra of a high resolution simulation'
publications = [
    'Mandelker2020a',
    ]